"""
    --- AUTO-GENERATED DOCSTRING ---
    This docstring is automatically generated by Agent Docstrings.
    Do not modify this block directly.
    
    Classes/Functions:
      - Functions:
        - parse_gitignore(gitignore_path: Path) -> Set[str] (line 47)
        - is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool (line 72)
        - load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]] (line 105)
        - process_file(path: Path, verbose: bool = False) -> None (line 268)
        - discover_and_process_files(directories: List[str], verbose: bool = False) -> None (line 321)
    --- END AUTO-GENERATED DOCSTRING ---
"""
from __future__ import annotations
"""
    --- AUTO-GENERATED DOCSTRING ---
    This docstring is automatically generated by Agent Docstrings.
    Do not modify this block directly.
    
    Classes/Functions:
      - Functions:
        - parse_gitignore(gitignore_path: Path) -> Set[str] (line 26)
        - is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool (line 44)
        - load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]] (line 70)
        - should_process_file(file_path: Path, root_dir: Path, ignore_patterns: Set[str], blacklist: Set[str], whitelist: Set[str]) -> bool (line 103)
        - process_file(path: Path, verbose: bool = False) -> None (line 139)
        - discover_and_process_files(directories: List[str], verbose: bool = False) -> None (line 195)
    --- END AUTO-GENERATED DOCSTRING ---
"""
import os
import fnmatch
from pathlib import Path
from typing import List, Callable, Dict, Tuple, Set

from .languages.common import (
    COMMENT_STYLES,
    ClassInfo,
    SignatureInfo,
    remove_agent_docstring,
    DOCSTRING_START_MARKER,
    DOCSTRING_END_MARKER,
)
from .languages import generic, kotlin, python, java, go, powershell, delphi


def parse_gitignore(gitignore_path: Path) -> Set[str]:
    """Parse .gitignore file and return set of ignore patterns.
    
    Args:
        gitignore_path (Path): Path to .gitignore file.
        
    Returns:
        Set[str]: Set of ignore patterns from .gitignore file.
    """
    patterns = set()
    if not gitignore_path.exists():
        return patterns
        
    try:
        with open(gitignore_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.add(line)
    except Exception:
        pass  # Silently ignore errors reading .gitignore
    
    return patterns


def is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool:
    """Check if a path should be ignored based on gitignore patterns.
    
    Args:
        path (Path): Path to check.
        ignore_patterns (Set[str]): Set of ignore patterns.
        root_dir (Path): Root directory for relative path calculation.
        
    Returns:
        bool: True if path should be ignored, False otherwise.
    """
    try:
        rel_path = path.relative_to(root_dir)
        rel_path_str = str(rel_path).replace('\\', '/')
        
        for pattern in ignore_patterns:
            # Handle directory patterns
            if pattern.endswith('/'):
                if fnmatch.fnmatch(rel_path_str + '/', pattern):
                    return True
            # Handle file patterns
            elif fnmatch.fnmatch(rel_path_str, pattern):
                return True
            # Check if any parent directory matches
            elif '/' not in pattern and any(fnmatch.fnmatch(part, pattern) for part in rel_path.parts):
                return True
                
    except ValueError:
        pass  # Path is not relative to root_dir
    
    return False


def load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]]:
    """Load blacklist and whitelist patterns from configuration files.
    
    Args:
        directory (Path): Directory to search for configuration files.
        
    Returns:
        Tuple[Set[str], Set[str]]: Tuple of (blacklist patterns, whitelist patterns).
    """
    blacklist = set()
    whitelist = set()
    
    # Check for .agent-docstrings-ignore file (blacklist)
    blacklist_file = directory / '.agent-docstrings-ignore'
    if blacklist_file.exists():
        try:
            with open(blacklist_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        blacklist.add(line)
        except Exception:
            pass
    
    # Check for .agent-docstrings-include file (whitelist)
    whitelist_file = directory / '.agent-docstrings-include'
    if whitelist_file.exists():
        try:
            with open(whitelist_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        whitelist.add(line)
        except Exception:
            pass
    
    return blacklist, whitelist


def should_process_file(file_path: Path, root_dir: Path, ignore_patterns: Set[str], 
                       blacklist: Set[str], whitelist: Set[str]) -> bool:
    """Determine if a file should be processed based on ignore patterns and lists.
    
    Args:
        file_path (Path): Path to the file.
        root_dir (Path): Root directory for relative path calculation.
        ignore_patterns (Set[str]): Gitignore patterns.
        blacklist (Set[str]): Additional blacklist patterns.
        whitelist (Set[str]): Whitelist patterns (if not empty, only these files are processed).
        
    Returns:
        bool: True if file should be processed, False otherwise.
    """
    # If whitelist exists and is not empty, only process files matching whitelist
    if whitelist:
        if not is_path_ignored(file_path, whitelist, root_dir):
            return False  # File not in whitelist
    
    # Check gitignore patterns
    if is_path_ignored(file_path, ignore_patterns, root_dir):
        return False
    
    # Check blacklist patterns
    if is_path_ignored(file_path, blacklist, root_dir):
        return False
    
    return True


# Mappings from file extension to language name and parser function
EXT_TO_LANG: Dict[str, str] = {
    ".py": "python",
    ".kt": "kotlin",
    ".js": "javascript",
    ".jsx": "javascript",
    ".ts": "typescript",
    ".tsx": "typescript",
    ".cs": "csharp",
    ".cpp": "cpp",
    ".cxx": "cpp",
    ".cc": "cpp",
    ".hpp": "cpp",
    ".h": "cpp",
    ".c": "c",
    ".java": "java",
    ".go": "go",
    ".ps1": "powershell",
    ".psm1": "powershell",
    ".pas": "delphi",
}

LANG_PARSERS: Dict[str, Callable[[List[str]], Tuple[List[ClassInfo], List[SignatureInfo]]]] = {
    "python": python.parse_python_file,
    "kotlin": kotlin.parse_kotlin_file,
    "javascript": lambda lines: generic.parse_generic_file(lines, "javascript"),
    "typescript": lambda lines: generic.parse_generic_file(lines, "typescript"),
    "csharp": lambda lines: generic.parse_generic_file(lines, "csharp"),
    "cpp": lambda lines: generic.parse_generic_file(lines, "cpp"),
    "c": lambda lines: generic.parse_generic_file(lines, "cpp"),  # C can be parsed like C++ (for functions)
    "java": java.parse_java_file,
    "go": go.parse_go_file,
    "powershell": powershell.parse_powershell_file,
    "delphi": delphi.parse_delphi_file,
}


def _format_header(
    classes: List[ClassInfo],
    functions: List[SignatureInfo],
    language: str,
    header_line_count: int,
) -> str:
    """Return a formatted header block for *language*.

    Args:
        classes (List[ClassInfo]): Parsed class hierarchy.
        functions (List[SignatureInfo]): Top-level functions.
        language (str): Canonical language identifier.
        header_line_count (int): Number of lines occupied by the header
            itself (including delimiters). Used to offset original line
            numbers so the recorded positions match the file *after*
            insertion.

    Returns:
        str: Fully-formed comment block ready to be written to the file.
    """
    style = COMMENT_STYLES[language]
    
    header_lines: List[str] = [
        f"{style.prefix}{DOCSTRING_START_MARKER}",
        f"{style.prefix}This docstring is automatically generated by Agent Docstrings.",
        f"{style.prefix}Do not modify this block directly.",
        f"{style.prefix}",
        f"{style.prefix}Classes/Functions:",
    ]

    def format_class(ci: ClassInfo, indent_level: int):
        indent = style.prefix + "  " * indent_level
        # Add the header line count to the original line number
        corrected_line = ci.line + header_line_count
        header_lines.append(f"{indent}- {ci.name} (line {corrected_line}):")
        for method in ci.methods:
            corrected_method_line = method.line + header_line_count
            header_lines.append(f"{indent}  - {method.signature} (line {corrected_method_line})")
        for inner in ci.inner_classes:
            format_class(inner, indent_level + 1)

    for ci in classes:
        format_class(ci, 0)

    if functions:
        header_lines.append(f"{style.prefix}  - Functions:")
        for func in functions:
            corrected_func_line = func.line + header_line_count
            header_lines.append(f"{style.prefix}    - {func.signature} (line {corrected_func_line})")

    header_lines.append(f"{style.prefix}{DOCSTRING_END_MARKER}")

    # Wrap in comment block
    full_header_text = [style.start] + header_lines + [style.end]
    return "\n".join(full_header_text)


def process_file(path: Path, verbose: bool = False) -> None:
    """Generate or refresh the header comment for *path*.

    Args:
        path (Path): Absolute or relative path to a source file.
        verbose (bool, optional): If *True*, progress messages are printed
            to *stdout*. Defaults to *False*.
    """
    ext = path.suffix.lower()
    if ext not in EXT_TO_LANG:
        return

    language = EXT_TO_LANG[ext]
    parser = LANG_PARSERS[language]

    try:
        original_content = path.read_text(encoding="utf-8", errors="ignore")
        content_no_header = remove_agent_docstring(original_content, language)
        lines = content_no_header.splitlines()

        classes, functions = parser(lines)

        if not classes and not functions:
            if verbose:
                print(f"Skipping {path} (no classes or functions found)")
            return

        # A preliminary header is needed to calculate its own line count for adjustments.
        preliminary_header = _format_header(classes, functions, language, 0)
        header_line_count = preliminary_header.count("\n") + 1

        # Now, format the final header with corrected line numbers.
        final_header = _format_header(classes, functions, language, header_line_count)

        # Re-add shebang if it was stripped with the header
        shebang = ""
        if original_content.startswith("#!"):
            shebang = original_content.splitlines()[0] + "\n"
            content_no_header = content_no_header.lstrip().split("\n", 1)[-1]
        
        new_content = f"{shebang}{final_header}\n{content_no_header}"

        if new_content.strip() != original_content.strip():
            path.write_text(new_content, encoding="utf-8")
            if verbose:
                print(f"Processed {language.capitalize()}: {path}")
        elif verbose:
            print(f"No changes for: {path}")

    except Exception as e:
        print(f"Error processing {path}: {e}")


def discover_and_process_files(directories: List[str], verbose: bool = False) -> None:
    """Recursively process all supported files inside *directories*.

    Args:
        directories (List[str]): White-list of root folders to scan.
        verbose (bool, optional): Enables per-file logging when *True*.
    """
    for dir_str in directories:
        directory = Path(dir_str)
        if not directory.is_dir():
            print(f"Warning: '{dir_str}' is not a valid directory. Skipping.")
            continue

        # Collect all gitignore patterns from the directory tree
        ignore_patterns = set()
        blacklist_patterns = set()
        whitelist_patterns = set()
        
        # Parse .gitignore files in the directory and its parents
        current_dir = directory.resolve()
        while current_dir != current_dir.parent:
            gitignore_path = current_dir / '.gitignore'
            if gitignore_path.exists():
                ignore_patterns.update(parse_gitignore(gitignore_path))
            current_dir = current_dir.parent
        
        # Load blacklist and whitelist from the root directory
        blacklist, whitelist = load_blacklist_whitelist(directory)
        blacklist_patterns.update(blacklist)
        whitelist_patterns.update(whitelist)

        for root, dirs, files in os.walk(directory):
            root_path = Path(root)
            
            # Filter directories to avoid walking into ignored ones
            dirs[:] = [d for d in dirs if not is_path_ignored(root_path / d, ignore_patterns, directory)]
            
            for file in files:
                file_path = root_path / file
                
                # Check if file should be processed
                if not should_process_file(file_path, directory, ignore_patterns, 
                                         blacklist_patterns, whitelist_patterns):
                    continue
                
                process_file(file_path, verbose) 