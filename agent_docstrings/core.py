"""
    --- AUTO-GENERATED DOCSTRING ---
    This docstring is automatically generated by Agent Docstrings.
    Do not modify this block directly.
    
    Classes/Functions:
      - Functions:
        - parse_gitignore(gitignore_path: Path) -> Set[str] (line 47)
        - is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool (line 72)
        - load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]] (line 105)
        - process_file(path: Path, verbose: bool = False) -> None (line 268)
        - discover_and_process_files(directories: List[str], verbose: bool = False) -> None (line 321)
    --- END AUTO-GENERATED DOCSTRING ---
"""
from __future__ import annotations
"""
    --- AUTO-GENERATED DOCSTRING ---
    This docstring is automatically generated by Agent Docstrings.
    Do not modify this block directly.
    
    Classes/Functions:
      - Functions:
        - parse_gitignore(gitignore_path: Path) -> Set[str] (line 26)
        - is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool (line 44)
        - load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]] (line 70)
        - should_process_file(file_path: Path, root_dir: Path, ignore_patterns: Set[str], blacklist: Set[str], whitelist: Set[str]) -> bool (line 103)
        - process_file(path: Path, verbose: bool = False) -> None (line 139)
        - discover_and_process_files(directories: List[str], verbose: bool = False) -> None (line 195)
    --- END AUTO-GENERATED DOCSTRING ---
"""
import os
import fnmatch
from pathlib import Path
from typing import List, Callable, Dict, Tuple, Set
import re

from .languages.common import (
    COMMENT_STYLES,
    ClassInfo,
    SignatureInfo,
    remove_agent_docstring,
    DOCSTRING_START_MARKER,
    DOCSTRING_END_MARKER,
)
from .languages import generic, kotlin, python, java, go, powershell, delphi


def parse_gitignore(gitignore_path: Path) -> Set[str]:
    """Parse .gitignore file and return set of ignore patterns.
    
    Args:
        gitignore_path (Path): Path to .gitignore file.
        
    Returns:
        Set[str]: Set of ignore patterns from .gitignore file.
    """
    patterns = set()
    if not gitignore_path.exists():
        return patterns
        
    try:
        with open(gitignore_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.add(line)
    except Exception:
        pass  # Silently ignore errors reading .gitignore
    
    return patterns


def is_path_ignored(path: Path, ignore_patterns: Set[str], root_dir: Path) -> bool:
    """Check if a path should be ignored based on gitignore patterns.
    
    Args:
        path (Path): Path to check.
        ignore_patterns (Set[str]): Set of ignore patterns.
        root_dir (Path): Root directory for relative path calculation.
        
    Returns:
        bool: True if path should be ignored, False otherwise.
    """
    try:
        rel_path = path.relative_to(root_dir)
        rel_path_str = str(rel_path).replace('\\', '/')
        
        for pattern in ignore_patterns:
            # Handle directory patterns
            if pattern.endswith('/'):
                if fnmatch.fnmatch(rel_path_str + '/', pattern):
                    return True
            # Handle file patterns
            elif fnmatch.fnmatch(rel_path_str, pattern):
                return True
            # Check if any parent directory matches
            elif '/' not in pattern and any(fnmatch.fnmatch(part, pattern) for part in rel_path.parts):
                return True
                
    except ValueError:
        pass  # Path is not relative to root_dir
    
    return False


def load_blacklist_whitelist(directory: Path) -> Tuple[Set[str], Set[str]]:
    """Load blacklist and whitelist patterns from configuration files.
    
    Args:
        directory (Path): Directory to search for configuration files.
        
    Returns:
        Tuple[Set[str], Set[str]]: Tuple of (blacklist patterns, whitelist patterns).
    """
    blacklist = set()
    whitelist = set()
    
    # Check for .agent-docstrings-ignore file (blacklist)
    blacklist_file = directory / '.agent-docstrings-ignore'
    if blacklist_file.exists():
        try:
            with open(blacklist_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        blacklist.add(line)
        except Exception:
            pass
    
    # Check for .agent-docstrings-include file (whitelist)
    whitelist_file = directory / '.agent-docstrings-include'
    if whitelist_file.exists():
        try:
            with open(whitelist_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        whitelist.add(line)
        except Exception:
            pass
    
    return blacklist, whitelist


def should_process_file(file_path: Path, root_dir: Path, ignore_patterns: Set[str], 
                       blacklist: Set[str], whitelist: Set[str]) -> bool:
    """Determine if a file should be processed based on ignore patterns and lists.
    
    Args:
        file_path (Path): Path to the file.
        root_dir (Path): Root directory for relative path calculation.
        ignore_patterns (Set[str]): Gitignore patterns.
        blacklist (Set[str]): Additional blacklist patterns.
        whitelist (Set[str]): Whitelist patterns (if not empty, only these files are processed).
        
    Returns:
        bool: True if file should be processed, False otherwise.
    """
    # If whitelist exists and is not empty, only process files matching whitelist
    if whitelist:
        if not is_path_ignored(file_path, whitelist, root_dir):
            return False  # File not in whitelist
    
    # Check gitignore patterns
    if is_path_ignored(file_path, ignore_patterns, root_dir):
        return False
    
    # Check blacklist patterns
    if is_path_ignored(file_path, blacklist, root_dir):
        return False
    
    return True


# Mappings from file extension to language name and parser function
EXT_TO_LANG: Dict[str, str] = {
    ".py": "python",
    ".kt": "kotlin",
    ".js": "javascript",
    ".jsx": "javascript",
    ".ts": "typescript",
    ".tsx": "typescript",
    ".cs": "csharp",
    ".cpp": "cpp",
    ".cxx": "cpp",
    ".cc": "cpp",
    ".hpp": "cpp",
    ".h": "cpp",
    ".c": "c",
    ".java": "java",
    ".go": "go",
    ".ps1": "powershell",
    ".psm1": "powershell",
    ".pas": "delphi",
}

LANG_PARSERS: Dict[str, Callable[[List[str]], Tuple[List[ClassInfo], List[SignatureInfo]]]] = {
    "python": python.parse_python_file,
    "kotlin": kotlin.parse_kotlin_file,
    "javascript": lambda lines: generic.parse_generic_file(lines, "javascript"),
    "typescript": lambda lines: generic.parse_generic_file(lines, "typescript"),
    "csharp": lambda lines: generic.parse_generic_file(lines, "csharp"),
    "cpp": lambda lines: generic.parse_generic_file(lines, "cpp"),
    "c": lambda lines: generic.parse_generic_file(lines, "cpp"),  # C can be parsed like C++ (for functions)
    "java": java.parse_java_file,
    "go": go.parse_go_file,
    "powershell": powershell.parse_powershell_file,
    "delphi": delphi.parse_delphi_file,
}


def _get_header_content_lines(
    classes: List[ClassInfo],
    functions: List[SignatureInfo],
    language: str,
    header_line_count: int,
) -> List[str]:
    """Return a list of lines for the header content."""
    style = COMMENT_STYLES[language]
    
    header_lines: List[str] = [
        f"{style.prefix}{DOCSTRING_START_MARKER}",
        f"{style.prefix}This docstring is automatically generated by Agent Docstrings.",
        f"{style.prefix}Do not modify this block directly.",
        f"{style.prefix}",
        f"{style.prefix}Classes/Functions:",
    ]

    def format_class(ci: ClassInfo, indent_level: int):
        indent = style.prefix + "  " * indent_level
        corrected_line = ci.line + header_line_count
        header_lines.append(f"{indent}- {ci.name} (line {corrected_line}):")
        for method in ci.methods:
            corrected_method_line = method.line + header_line_count
            header_lines.append(f"{indent}  - {method.signature} (line {corrected_method_line})")
        for inner in ci.inner_classes:
            format_class(inner, indent_level + 1)

    for ci in classes:
        format_class(ci, 0)

    if functions:
        header_lines.append(f"{style.prefix}  - Functions:")
        for func in functions:
            corrected_func_line = func.line + header_line_count
            header_lines.append(f"{style.prefix}    - {func.signature} (line {corrected_func_line})")

    header_lines.append(f"{style.prefix}{DOCSTRING_END_MARKER}")
    return header_lines


def _format_header(
    classes: List[ClassInfo],
    functions: List[SignatureInfo],
    language: str,
    header_line_count: int,
) -> str:
    """Return a formatted header block for *language*."""
    style = COMMENT_STYLES[language]
    header_content_lines = _get_header_content_lines(classes, functions, language, header_line_count)
    
    # Wrap in comment block
    full_header_text = [style.start] + header_content_lines + [style.end]
    return "\n".join(full_header_text)


def process_file(path: Path, verbose: bool = False) -> None:
    """Generate or refresh the header comment for *path*.

    Args:
        path (Path): Absolute or relative path to a source file.
        verbose (bool, optional): If *True*, progress messages are printed
            to *stdout*. Defaults to *False*.
    """
    ext = path.suffix.lower()
    if ext not in EXT_TO_LANG:
        return

    language = EXT_TO_LANG[ext]
    parser = LANG_PARSERS[language]
    style = COMMENT_STYLES[language]

    try:
        original_content = path.read_text(encoding="utf-8", errors="ignore")
        
        # We no longer strip the header first. We will parse the code and then decide how to inject the new header.
        lines = original_content.splitlines()

        # Extract shebang and encoding comment from the top of the file
        file_prefix_lines = []
        body_start_index = 0

        if len(lines) > body_start_index and lines[body_start_index].startswith("#!"):
            file_prefix_lines.append(lines[body_start_index])
            body_start_index += 1
        
        if len(lines) > body_start_index and re.match(r"^[ \t\f]*#.*?coding[:=]\s*([-\w.]+)", lines[body_start_index]):
            file_prefix_lines.append(lines[body_start_index])
            body_start_index += 1
        
        # To parse functions/classes, we need the code without any file-level docstring.
        # Let's find the code body.
        temp_code_body = "\n".join(lines[body_start_index:])
        docstring_end_pos = -1

        # Simple check for module docstring start
        if temp_code_body.lstrip().startswith(style.start):
            end_marker_pos = temp_code_body.find(style.end, len(style.start))
            if end_marker_pos != -1:
                docstring_end_pos = end_marker_pos + len(style.end)

        code_to_parse = temp_code_body[docstring_end_pos:] if docstring_end_pos != -1 else temp_code_body
        
        classes, functions = parser(code_to_parse.splitlines())

        if not classes and not functions:
            if verbose:
                print(f"Skipping {path} (no classes or functions found)")
            return

        preliminary_header_lines = _get_header_content_lines(classes, functions, language, 0)
        header_line_count = len(preliminary_header_lines)

        final_header_lines = _get_header_content_lines(classes, functions, language, header_line_count)
        final_header_content = "\n".join(final_header_lines)

        # Now, let's inject the new header into the original content
        file_prefix = "\n".join(file_prefix_lines)
        code_body = "\n".join(lines[body_start_index:])
        
        new_content = ""

        # Pattern to find an existing agent docstring content (inside a docstring)
        agent_content_pattern = re.compile(
            rf"{re.escape(style.prefix)}{re.escape(DOCSTRING_START_MARKER)}.*?{re.escape(style.prefix)}{re.escape(DOCSTRING_END_MARKER)}",
            re.DOTALL
        )

        agent_match = agent_content_pattern.search(code_body)

        if agent_match:
            # Case 1: An agent docstring already exists. Replace its content.
            new_code_body = agent_content_pattern.sub(final_header_content, code_body, count=1)
        else:
            # Case 2: No agent docstring. Look for a manual one or create a new block.
            docstring_start_pos = code_body.lstrip().find(style.start)
            
            if docstring_start_pos == 0:
                # Case 2a: A manual docstring exists. Inject our content into it.
                leading_whitespace = code_body[:code_body.find(style.start)]
                content_after_delimiter_pos = code_body.find(style.start) + len(style.start)
                
                # Check if there is content on the same line as the opening delimiter
                rest_of_line = code_body[content_after_delimiter_pos:].split('\n')[0]
                
                insertion_text = f"\n{final_header_content}\n"
                
                # If the docstring is like """Docstring.""" on one line, add a newline.
                if rest_of_line.strip() and style.end in rest_of_line:
                    insertion_text = f"\n{final_header_content}"

                new_code_body = (
                    leading_whitespace +
                    style.start +
                    insertion_text +
                    code_body[content_after_delimiter_pos:].lstrip()
                )
            else:
                # Case 2b: No docstring found. Create a new one.
                full_header_block = f"{style.start}\n{final_header_content}\n{style.end}"
                new_code_body = f"{full_header_block}\n\n{code_body.lstrip()}"

        new_content_parts = []
        if file_prefix:
            new_content_parts.append(file_prefix)
        new_content_parts.append(new_code_body)
        new_content = "\n".join(new_content_parts)
        
        if new_content.strip() != original_content.strip():
            # * Using open with newline='\n' to force LF line endings, which is
            # * standard for git projects and avoids CRLF<->LF conversion issues.
            with path.open("w", encoding="utf-8", newline="\n") as f:
                f.write(new_content)
            
            if verbose:
                print(f"Processed {language.capitalize()}: {path}")
        elif verbose:
            print(f"No changes for: {path}")

    except Exception as e:
        print(f"Error processing {path}: {e}")


def discover_and_process_files(directories: List[str], verbose: bool = False) -> None:
    """Recursively process all supported files inside *directories*.

    Args:
        directories (List[str]): White-list of root folders to scan.
        verbose (bool, optional): Enables per-file logging when *True*.
    """
    for dir_str in directories:
        directory = Path(dir_str)
        if not directory.is_dir():
            print(f"Warning: '{dir_str}' is not a valid directory. Skipping.")
            continue

        # Collect all gitignore patterns from the directory tree
        ignore_patterns = set()
        blacklist_patterns = set()
        whitelist_patterns = set()
        
        # Parse .gitignore files in the directory and its parents
        current_dir = directory.resolve()
        while current_dir != current_dir.parent:
            gitignore_path = current_dir / '.gitignore'
            if gitignore_path.exists():
                ignore_patterns.update(parse_gitignore(gitignore_path))
            current_dir = current_dir.parent
        
        # Load blacklist and whitelist from the root directory
        blacklist, whitelist = load_blacklist_whitelist(directory)
        blacklist_patterns.update(blacklist)
        whitelist_patterns.update(whitelist)

        for root, dirs, files in os.walk(directory):
            root_path = Path(root)
            
            # Filter directories to avoid walking into ignored ones
            dirs[:] = [d for d in dirs if not is_path_ignored(root_path / d, ignore_patterns, directory)]
            
            for file in files:
                file_path = root_path / file
                
                # Check if file should be processed
                if not should_process_file(file_path, directory, ignore_patterns, 
                                         blacklist_patterns, whitelist_patterns):
                    continue
                
                process_file(file_path, verbose) 